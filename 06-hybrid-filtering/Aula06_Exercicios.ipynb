{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58dbcadb",
   "metadata": {},
   "source": [
    "## Aula 06 - Filtragem Híbrida - Exercícios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc39da2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from caserec.recommenders.rating_prediction.item_attribute_knn import ItemAttributeKNN\n",
    "import wget\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.sparse import coo_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1be56cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! rm -fr ./dataset/ ./features/ ./outputs/ ./precomputed/ ./ml-20m-compact.tar.gz ./ml-20m-features.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af07eb8",
   "metadata": {},
   "source": [
    "### Importar base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2652d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% [....................................................] 65019041 / 65019041\n",
      "Saved under ml-20m-compact.tar.gz\n",
      "dataset/\n",
      "dataset/tags_sample.csv\n",
      "dataset/._.DS_Store\n",
      "dataset/.DS_Store\n",
      "dataset/movies_sample.csv\n",
      "dataset/._genome-tags.csv\n",
      "dataset/genome-tags.csv\n",
      "dataset/._ml-youtube.csv\n",
      "dataset/ml-youtube.csv\n",
      "dataset/._genome-scores.csv\n",
      "dataset/genome-scores.csv\n",
      "dataset/ratings_sample.csv\n"
     ]
    }
   ],
   "source": [
    "!python3 -m wget https://github.com/mmanzato/MBABigData/raw/master/ml-20m-compact.tar.gz\n",
    "!tar -xvzf ml-20m-compact.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "283e7b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% [......................................................] 5996435 / 5996435\n",
      "Saved under ml-20m-features.tar.gz\n",
      "features/\n",
      "features/._m4infus_max_histogram_300_sn.arq\n",
      "features/m4infus_max_histogram_300_sn.arq\n",
      "features/._mm_avg_histogram_100_sn.arq\n",
      "features/mm_avg_histogram_100_sn.arq\n",
      "features/._visual_histogram_100_sn.arq\n",
      "features/visual_histogram_100_sn.arq\n",
      "features/._visual_histogram_50_sn.arq\n",
      "features/visual_histogram_50_sn.arq\n",
      "features/._aural_histogram_50.arq\n",
      "features/aural_histogram_50.arq\n",
      "features/._mm_max_histogram_300.arq\n",
      "features/mm_max_histogram_300.arq\n",
      "features/._m4infus_max_histogram_50.arq\n",
      "features/m4infus_max_histogram_50.arq\n",
      "features/._mm_max_histogram_100.arq\n",
      "features/mm_max_histogram_100.arq\n",
      "features/._mm_max_histogram_50_sn.arq\n",
      "features/mm_max_histogram_50_sn.arq\n",
      "features/._visual_histogram_100.arq\n",
      "features/visual_histogram_100.arq\n",
      "features/._visual_histogram_300.arq\n",
      "features/visual_histogram_300.arq\n",
      "features/._aural_histogram_100_sn.arq\n",
      "features/aural_histogram_100_sn.arq\n",
      "features/._mm_avg_histogram_100.arq\n",
      "features/mm_avg_histogram_100.arq\n",
      "features/._mm_max_histogram_100_sn.arq\n",
      "features/mm_max_histogram_100_sn.arq\n",
      "features/._mm_sum_histogram_100_sn.arq\n",
      "features/mm_sum_histogram_100_sn.arq\n",
      "features/._mm_avg_histogram_300.arq\n",
      "features/mm_avg_histogram_300.arq\n",
      "features/._visual_histogram_300_sn.arq\n",
      "features/visual_histogram_300_sn.arq\n",
      "features/._mm_avg_histogram_300_sn.arq\n",
      "features/mm_avg_histogram_300_sn.arq\n",
      "features/._m4infus_max_histogram_100.arq\n",
      "features/m4infus_max_histogram_100.arq\n",
      "features/._m4infus_max_histogram_100_sn.arq\n",
      "features/m4infus_max_histogram_100_sn.arq\n",
      "features/._mm_sum_histogram_50_sn.arq\n",
      "features/mm_sum_histogram_50_sn.arq\n",
      "features/._m4infus_max_histogram_300.arq\n",
      "features/m4infus_max_histogram_300.arq\n",
      "features/._mm_avg_histogram_50_sn.arq\n",
      "features/mm_avg_histogram_50_sn.arq\n",
      "features/._mm_sum_histogram_50.arq\n",
      "features/mm_sum_histogram_50.arq\n",
      "features/._visual_histogram_50.arq\n",
      "features/visual_histogram_50.arq\n",
      "features/._aural_histogram_50_sn.arq\n",
      "features/aural_histogram_50_sn.arq\n",
      "features/._mm_sum_histogram_300.arq\n",
      "features/mm_sum_histogram_300.arq\n",
      "features/._m4infus_max_histogram_50_sn.arq\n",
      "features/m4infus_max_histogram_50_sn.arq\n",
      "features/._mm_max_histogram_50.arq\n",
      "features/mm_max_histogram_50.arq\n",
      "features/._mm_avg_histogram_50.arq\n",
      "features/mm_avg_histogram_50.arq\n",
      "features/._mm_max_histogram_300_sn.arq\n",
      "features/mm_max_histogram_300_sn.arq\n",
      "features/._mm_sum_histogram_300_sn.arq\n",
      "features/mm_sum_histogram_300_sn.arq\n",
      "features/._mm_sum_histogram_100.arq\n",
      "features/mm_sum_histogram_100.arq\n",
      "features/._aural_histogram_300.arq\n",
      "features/aural_histogram_300.arq\n",
      "features/._aural_histogram_300_sn.arq\n",
      "features/aural_histogram_300_sn.arq\n",
      "features/._aural_histogram_100.arq\n",
      "features/aural_histogram_100.arq\n"
     ]
    }
   ],
   "source": [
    "!python3 -m wget https://github.com/mmanzato/MBABigData/raw/master/ml-20m-features.tar.gz\n",
    "! tar -xvzf ml-20m-features.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de8b897c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Enemy Mine (1985)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Beautiful Thing (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Aristocats, The (1970)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>American Psycho (2000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Bowling for Columbine (2002)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating                         title\n",
       "0       0        0     5.0             Enemy Mine (1985)\n",
       "1       0        1     4.5        Beautiful Thing (1996)\n",
       "2       0        2     4.0        Aristocats, The (1970)\n",
       "3       0        3     2.0        American Psycho (2000)\n",
       "4       0        4     5.0  Bowling for Columbine (2002)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading\n",
    "movies = pd.read_csv('dataset/movies_sample.csv')\n",
    "ratings = pd.read_csv('dataset/ratings_sample.csv')\n",
    "tags = pd.read_csv('dataset/tags_sample.csv')\n",
    "\n",
    "\n",
    "# Merging\n",
    "df = ratings[['userId', 'movieId', 'rating']].merge(movies[['movieId', 'title']], on='movieId')\n",
    "\n",
    "\n",
    "# Mapping\n",
    "map_users = {user: idx for idx, user in enumerate(df.userId.unique())}\n",
    "map_items = {movie: idx for idx, movie in enumerate(df.movieId.unique())}\n",
    "\n",
    "df['userId'] = df['userId'].map(map_users)\n",
    "df['movieId'] = df['movieId'].map(map_items)\n",
    "\n",
    "ratings['userId'] = ratings['userId'].map(map_users)\n",
    "ratings['movieId'] = ratings['movieId'].map(map_items)\n",
    "\n",
    "movies['movieId'] = movies['movieId'].map(map_items)\n",
    "\n",
    "tags['userId'] = tags['userId'].map(map_users)\n",
    "tags['movieId'] = tags['movieId'].map(map_items)\n",
    "\n",
    "map_title = {movie: title for movie, title in zip(movies['movieId'], movies['title'])}\n",
    "\n",
    "\n",
    "# Display\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39ee283a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading features\n",
    "with open('./features/visual_histogram_50.arq', 'rb') as arq_visual_features:\n",
    "    visual_features = pickle.load(arq_visual_features)\n",
    "\n",
    "with open('./features/aural_histogram_50.arq', 'rb') as arq_aural_features:\n",
    "    aural_features = pickle.load(arq_aural_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0eb0ba",
   "metadata": {},
   "source": [
    "## Funções Auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34dec16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "def compute_item_sim(df):\n",
    "    # Pivot the dataframe to have movies as columns and users as rows, with ratings as values\n",
    "    user_movie_matrix = df.pivot(index='userId', columns='movieId', values='rating').fillna(0)\n",
    "    \n",
    "    # Compute the cosine similarity\n",
    "    cosine_sim_matrix = cosine_similarity(user_movie_matrix.T)  # Transpose to have movies as rows\n",
    "    \n",
    "    # Get movie ids\n",
    "    movie_ids = user_movie_matrix.columns\n",
    "    \n",
    "    # Create a sparse matrix representation using coo_matrix\n",
    "    sim_sparse = coo_matrix(cosine_sim_matrix)\n",
    "    \n",
    "    # Create a dataframe from the sparse matrix\n",
    "    sim_df = pd.DataFrame({\n",
    "        'movieId1': movie_ids[sim_sparse.row],\n",
    "        'movieId2': movie_ids[sim_sparse.col],\n",
    "        'similarity': sim_sparse.data\n",
    "    })\n",
    "    \n",
    "    # Remove self-similarities (where movieId1 == movieId2)\n",
    "    sim_df = sim_df[sim_df['movieId1'] != sim_df['movieId2']].reset_index(drop=True)\n",
    "    \n",
    "    # Now, add missing pairs with zero similarity\n",
    "    all_movie_pairs = pd.MultiIndex.from_product([movie_ids, movie_ids], names=[\"movieId1\", \"movieId2\"]).to_frame(index=False)\n",
    "    \n",
    "    # Merge the existing similarities with all pairs\n",
    "    final_sim_df = pd.merge(all_movie_pairs, sim_df, on=[\"movieId1\", \"movieId2\"], how=\"left\").fillna(0)\n",
    "    \n",
    "    # Remove self-similarities again if needed\n",
    "    final_sim_df = final_sim_df[final_sim_df['movieId1'] != final_sim_df['movieId2']].reset_index(drop=True)\n",
    "    \n",
    "    return final_sim_df\n",
    "\n",
    "def np_compute_feature_sim(features):\n",
    "    # Convert to numpy array\n",
    "    data = np.array(features)\n",
    "\n",
    "    # Calculate norms (magnitude of vectors)\n",
    "    norms = np.linalg.norm(data, axis=1, keepdims=True)\n",
    "\n",
    "    # Filter out rows with all zeros\n",
    "    mask = (norms != 0).flatten()  # Flatten the mask to make it 1D\n",
    "\n",
    "    data = data[mask]\n",
    "    norms = norms[mask]\n",
    "\n",
    "    # Normalize data\n",
    "    normalized_data = data / norms\n",
    "\n",
    "    # Calculate cosine similarity matrix (dot product of normalized vectors)\n",
    "    cosine_similarity_matrix = np.dot(normalized_data, normalized_data.T)\n",
    "\n",
    "    return cosine_similarity_matrix\n",
    "\n",
    "\n",
    "def np_to_pd_matrix(matrix):\n",
    "        # Create row and column indices for all elements\n",
    "    rows, cols = np.indices(matrix.shape)\n",
    "    \n",
    "    # Flatten the indices and values to create the DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'i': rows.flatten(),\n",
    "        'j': cols.flatten(),\n",
    "        'value': matrix.flatten()\n",
    "    })\n",
    "    \n",
    "    return df.fillna(0)\n",
    "\n",
    "\n",
    "def compute_feature_sim(features):\n",
    "    return (\n",
    "        np_to_pd_matrix(np_compute_feature_sim(features))\n",
    "        .rename(columns={\n",
    "            'i': 'movieId1', \n",
    "            'j': 'movieId2', \n",
    "            'value': 'similarity'\n",
    "        })\n",
    "    )\n",
    "\n",
    "    \n",
    "\n",
    "# returns the number of users that have rated both items i1 and i2\n",
    "def coincidence(i1, i2):\n",
    "    return len(set(df[df['movieId'] == i1]['userId']).intersection(set(df[df['movieId'] == i2]['userId'])))\n",
    "               \n",
    "def gen_coincidence_mat(df):\n",
    "    n_items = df['movieId'].nunique()\n",
    "    coincidence_mat = np.zeros((n_items, n_items))\n",
    "    for i in range(n_items):\n",
    "        for j in range(i+1, n_items):\n",
    "            coincidence_mat[i, j] = coincidence(i, j)\n",
    "            coincidence_mat[j, i] = coincidence_mat[i, j]\n",
    "            \n",
    "    return np_to_pd_matrix(coincidence_mat)\n",
    "\n",
    "\n",
    "def gen_coincidence_mat(df):\n",
    "    # Get unique users and movies\n",
    "    user_ids = df['userId'].astype('category').cat.codes\n",
    "    movie_ids = df['movieId'].astype('category').cat.codes\n",
    "    num_users = user_ids.max() + 1\n",
    "    num_movies = movie_ids.max() + 1\n",
    "    \n",
    "    # Create a sparse binary matrix where rows are users and columns are movies\n",
    "    ratings_sparse = coo_matrix((df['rating'], (user_ids, movie_ids)), shape=(num_users, num_movies))\n",
    "    \n",
    "    # Multiply the sparse matrix by its transpose to get the coincidence matrix\n",
    "    coincidence_matrix = ratings_sparse.T @ ratings_sparse\n",
    "    \n",
    "    # Extract non-zero values (coincidence counts)\n",
    "    coincidence_matrix_coo = coo_matrix(coincidence_matrix)\n",
    "    \n",
    "    # Create the resulting dataframe with movieId pairs and their coincidence count\n",
    "    coincidence_df = pd.DataFrame({\n",
    "        'movieId1': coincidence_matrix_coo.row,\n",
    "        'movieId2': coincidence_matrix_coo.col,\n",
    "        'coincidence': coincidence_matrix_coo.data\n",
    "    })\n",
    "    \n",
    "    # Map movieId1 and movieId2 back to original movie IDs\n",
    "    movie_id_map = df[['movieId']].drop_duplicates().reset_index(drop=True)\n",
    "    coincidence_df['movieId1'] = movie_id_map.iloc[coincidence_df['movieId1'].values]['movieId'].values\n",
    "    coincidence_df['movieId2'] = movie_id_map.iloc[coincidence_df['movieId2'].values]['movieId'].values\n",
    "    \n",
    "    return coincidence_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42379b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def gen_hybrid_similarity_matrix(df, L1, coincidence, similarities, weights):\n",
    "    # Create an empty list to store the results\n",
    "    result = []\n",
    "\n",
    "    # Create a dictionary for quick lookup of coincidence values\n",
    "    coincidence_dict = {(row['movieId1'], row['movieId2']): row['coincidence'] for _, row in coincidence.iterrows()}\n",
    "\n",
    "    # Create a list of dictionaries for quick lookup of similarities\n",
    "    similarity_dicts = [\n",
    "        {(row['movieId1'], row['movieId2']): row['similarity'] for _, row in sim_df.iterrows()} \n",
    "        for sim_df in similarities\n",
    "    ]\n",
    "\n",
    "    # Iterate over unique movie pairs in the df\n",
    "    unique_movies = df['movieId'].unique()\n",
    "    for i, movieId1 in enumerate(unique_movies):\n",
    "        for movieId2 in unique_movies[i+1:]:\n",
    "            # Default similarity to None\n",
    "            similarity = None\n",
    "            \n",
    "            # Check for coincidence level\n",
    "            coincidence_value = coincidence_dict.get((movieId1, movieId2), 0)\n",
    "\n",
    "            if coincidence_value > L1:\n",
    "                # If coincidence is greater than L1, use the first similarity matrix\n",
    "                similarity = similarity_dicts[0].get((movieId1, movieId2), 0)\n",
    "            else:\n",
    "                # If coincidence is less than or equal to L1, calculate weighted average similarity\n",
    "                weighted_sum = 0\n",
    "                total_weight = 0\n",
    "                for idx, sim_dict in enumerate(similarity_dicts):\n",
    "                    sim_value = sim_dict.get((movieId1, movieId2), 0)\n",
    "                    weighted_sum += sim_value * weights[idx]\n",
    "                    total_weight += weights[idx]\n",
    "                \n",
    "                # Calculate the weighted average similarity\n",
    "                if total_weight > 0:\n",
    "                    similarity = weighted_sum / total_weight\n",
    "                else:\n",
    "                    similarity = 0\n",
    "\n",
    "            # Store the result as a tuple (movieId1, movieId2, similarity)\n",
    "            result.append((movieId1, movieId2, similarity))\n",
    "\n",
    "    # Convert the result list into a DataFrame\n",
    "    similarity_matrix = pd.DataFrame(result, columns=['movieId1', 'movieId2', 'similarity'])\n",
    "\n",
    "    return similarity_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5dff0c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_similarity_matrices(df1, df2, tol=1e-6):\n",
    "    \"\"\"\n",
    "    Compares two similarity matrices (pandas DataFrames) to see if they are the same.\n",
    "    \n",
    "    Parameters:\n",
    "    df1, df2: DataFrames with columns ['movieId1', 'movieId2', 'similarity'].\n",
    "    tol: tolerance for comparing floating-point similarity values.\n",
    "\n",
    "    Returns:\n",
    "    bool: True if the two DataFrames are equal within the given tolerance, False otherwise.\n",
    "    \"\"\"\n",
    "    # First, check if they have the same shape\n",
    "    if df1.shape != df2.shape:\n",
    "        print(\"DataFrames have different shapes.\")\n",
    "        return False\n",
    "\n",
    "    # Then, sort both DataFrames by movieId1 and movieId2 to ensure the comparison order is the same\n",
    "    df1_sorted = df1.sort_values(by=['movieId1', 'movieId2']).reset_index(drop=True)\n",
    "    df2_sorted = df2.sort_values(by=['movieId1', 'movieId2']).reset_index(drop=True)\n",
    "\n",
    "    # Now, compare the movieId1 and movieId2 columns\n",
    "    if not df1_sorted[['movieId1', 'movieId2']].equals(df2_sorted[['movieId1', 'movieId2']]):\n",
    "        print(\"Movie ID pairs do not match.\")\n",
    "        return False\n",
    "\n",
    "    # Compare the similarity values using numpy's isclose function with the given tolerance\n",
    "    if not np.allclose(df1_sorted['similarity'], df2_sorted['similarity'], atol=tol):\n",
    "        print(\"Similarity values do not match within tolerance.\")\n",
    "        return False\n",
    "\n",
    "    # If all checks pass, the DataFrames are considered equal\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6eedbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def fast_gen_hybrid_similarity_matrix(df, L1, coincidence, similarities, weights):\n",
    "    # Step 1: Merge the coincidence DataFrame with the first similarity DataFrame\n",
    "    merged_df = coincidence.merge(similarities[0], on=['movieId1', 'movieId2'], how='left', suffixes=('', '_sim1'))\n",
    "\n",
    "    # Step 2: Check if the coincidence level is greater than L1\n",
    "    mask = merged_df['coincidence'] > L1\n",
    "\n",
    "    # Step 3: For movie pairs where coincidence > L1, use the first similarity matrix directly\n",
    "    merged_df['similarity'] = np.where(mask, merged_df['similarity'], np.nan)\n",
    "    \n",
    "    # If there is only one similarity matrix, return the result immediately\n",
    "    if len(similarities) <= 1:\n",
    "        return merged_df[['movieId1', 'movieId2', 'similarity']].dropna()\n",
    "\n",
    "    # Merge additional similarity matrices\n",
    "    for i, sim_df in enumerate(similarities[1:], start=1):\n",
    "        merged_df = merged_df.merge(\n",
    "            sim_df[['movieId1', 'movieId2', 'similarity']].rename(columns={'similarity': f'sim_{i}'}),\n",
    "            on=['movieId1', 'movieId2'], \n",
    "            how='left'\n",
    "        )\n",
    "\n",
    "    # Now we need to handle missing similarity values individually\n",
    "    # We'll calculate the weighted sum for pairs where coincidence <= L1\n",
    "    weighted_sums = np.zeros(len(merged_df))\n",
    "    total_weight = np.zeros(len(merged_df))\n",
    "\n",
    "    for i in range(len(similarities)):\n",
    "        sim_column = f'sim_{i}' if i > 0 else 'similarity'\n",
    "\n",
    "        # Handle NaN values manually during the summation, like in the first function\n",
    "        sim_values = merged_df[sim_column].fillna(0)  # Replace NaNs with 0 for the sum\n",
    "        weighted_sums += sim_values * weights[i]\n",
    "        total_weight += (merged_df[sim_column].notna()) * weights[i]  # Count non-NaN similarities for the total weight\n",
    "\n",
    "    # Assign weighted average where necessary (for pairs where coincidence <= L1)\n",
    "    non_masked_indices = ~mask\n",
    "    valid_indices = total_weight[non_masked_indices] > 0\n",
    "\n",
    "    # Ensure proper calculation where there is valid data\n",
    "    merged_df.loc[non_masked_indices, 'similarity'] = np.where(\n",
    "        valid_indices,\n",
    "        weighted_sums[non_masked_indices] / total_weight[non_masked_indices],\n",
    "        0  # If total_weight is 0, the result is 0 (no valid similarities)\n",
    "    )\n",
    "\n",
    "    # Step 5: Return the final similarity DataFrame\n",
    "    return merged_df[['movieId1', 'movieId2', 'similarity']].dropna()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8802fe88",
   "metadata": {},
   "source": [
    "## Pre-computando valores intermédiários"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b5b6fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the folder structure\n",
    "! mkdir -p precomputed\n",
    "! mkdir -p outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44d96dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_df = df.copy()\n",
    "bin_df['rating'] = bin_df['rating'].apply(lambda x: 1 if x > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "924a10e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "train, test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Save split to disk \n",
    "train.to_csv('precomputed/train.csv', index=False, sep='\\t', header=False)\n",
    "test.to_csv('precomputed/test.csv', index=False, sep='\\t', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed5e69bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save tags to disk\n",
    "tags[['movieId', 'tag']].to_csv('precomputed/tags.csv', index=False, sep='\\t', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b9e7af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map ratings to one if rating >= 4, zero otherwise\n",
    "train['rating'] = train['rating'].apply(lambda x: 1 if x > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55f08e37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId1</th>\n",
       "      <th>movieId2</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.040850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.141544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.183813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.210518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.306905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId1  movieId2  similarity\n",
       "0         0         1    0.040850\n",
       "1         0         2    0.141544\n",
       "2         0         3    0.183813\n",
       "3         0         4    0.210518\n",
       "4         0         5    0.306905"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute item-item cosine similarity based of ratings\n",
    "rating_sim = compute_item_sim(df)\n",
    "\n",
    "# Save rating similarity to disk\n",
    "rating_sim.to_csv('precomputed/item_cos_rating_sim.csv', index=False, sep='\\t', header=False)\n",
    "\n",
    "rating_sim.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6e61277b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId1</th>\n",
       "      <th>movieId2</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.711958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.487788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.247959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.736261</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId1  movieId2  similarity\n",
       "0         0         0    1.000000\n",
       "1         0         1    0.711958\n",
       "2         0         2    0.487788\n",
       "3         0         3    0.247959\n",
       "4         0         4    0.736261"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute item-item cosine similarity based on visual features\n",
    "visual_sim =  compute_feature_sim(visual_features)\n",
    "\n",
    "# Drop values above df.movieId.max()\n",
    "# visual_sim = visual_sim[(visual_sim['movieId1'] <= df['movieId'].max()) & (visual_sim['movieId2'] <= df['movieId'].max())]\n",
    "\n",
    "# Save visual similarity to disk\n",
    "visual_sim.to_csv('precomputed/item_cos_visual_sim.csv', index=False, sep='\\t', header=False)\n",
    "\n",
    "visual_sim.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "55bd459c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId1</th>\n",
       "      <th>movieId2</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.065120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.025738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.006057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId1  movieId2  similarity\n",
       "0         0         0    1.000000\n",
       "1         0         1    0.065120\n",
       "2         0         2    0.025738\n",
       "3         0         3    0.006057\n",
       "4         0         4    0.000064"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute item-item cosine similarity based on aural features\n",
    "aural_sim = compute_feature_sim(aural_features)\n",
    "\n",
    "# Drop values above df.movieId.max()\n",
    "aural_sim = aural_sim[(aural_sim['movieId1'] <= df['movieId'].max()) & (aural_sim['movieId2'] <= df['movieId'].max())]\n",
    "\n",
    "# Save aural similarity to disk\n",
    "aural_sim.to_csv('precomputed/item_cos_aural_sim.csv', index=False, sep='\\t', header=False)\n",
    "\n",
    "aural_sim.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "572f9993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId1</th>\n",
       "      <th>movieId2</th>\n",
       "      <th>coincidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>348</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>302</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>225</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>372</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>409</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId1  movieId2  coincidence\n",
       "0         0       348            1\n",
       "1         0       302            1\n",
       "2         0       225            1\n",
       "3         0       372            1\n",
       "4         0       409            1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute item-item coincidence matrix\n",
    "coincidence_mat = gen_coincidence_mat(bin_df)\n",
    "\n",
    "# Save coincidence matrix to disk\n",
    "coincidence_mat.to_csv('precomputed/item_coincidence_mat.csv', index=False, sep='\\t', header=False)\n",
    "\n",
    "coincidence_mat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7cf1483d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId1</th>\n",
       "      <th>movieId2</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.040850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.141544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.183813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.210518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.306905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId1  movieId2  similarity\n",
       "0         0         1    0.040850\n",
       "1         0         2    0.141544\n",
       "2         0         3    0.183813\n",
       "3         0         4    0.210518\n",
       "4         0         5    0.306905"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute hybrid similarity matrix\n",
    "hybrid_mat = gen_hybrid_similarity_matrix(bin_df, 10, coincidence_mat, [rating_sim, aural_sim, visual_sim], [1, 2, 3])\n",
    "\n",
    "# Save hybrid similarity matrix to disk\n",
    "hybrid_mat.to_csv('precomputed/item_hybrid_sim.csv', index=False, sep='\\t', header=False)\n",
    "\n",
    "hybrid_mat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3c653303",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "415"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hybrid_mat.movieId1.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8a8961",
   "metadata": {},
   "source": [
    "***Exercício 01:*** Implemente uma hibridização monolítica/combinação usando a seguinte heurística:\n",
    "- Uso do algoritmo ItemAtributeKNN, sendo a hibridização feita no cálculo das similaridades entre os itens.\n",
    "- Se a quantidade de usuários que avaliaram ambos os itens for maior que um limiar L1, calcule a similaridade entre esses itens usando cosseno aplicado à representação baseada em notas.\n",
    "- Caso contrário, calcule a similaridade entre os itens usando tags, características visuais e características aurais. Pondere cada uma das modalidades via pesos passados por parâmetro. \n",
    "\n",
    "Compare os resultados do algoritmo híbrido com as versões isoladas do mesmo algoritmo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9d7eb3ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Case Recommender: Rating Prediction > Item Attribute KNN Algorithm]\n",
      "\n",
      "train data:: 11090 users and 413 items (152496 interactions) | sparsity:: 96.67%\n",
      "test data:: 10551 users and 333 items (38125 interactions) | sparsity:: 98.91%\n",
      "\n",
      "training_time:: 4.198962 sec\n",
      "prediction_time:: 0.270922 sec\n",
      "Eval:: MAE: 0.732208 RMSE: 0.970678 \n"
     ]
    }
   ],
   "source": [
    "ItemAttributeKNN(\n",
    "    train_file='precomputed/train.csv',\n",
    "    test_file='precomputed/test.csv',\n",
    "    output_file='outputs/base_predictions.csv',\n",
    "    # metadata_file='precomputed/tags.csv', \n",
    "    as_similar_first=True,\n",
    "    k_neighbors=5,\n",
    "    similarity_file='precomputed/item_cos_rating_sim.csv',\n",
    ").compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d59f6205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Case Recommender: Rating Prediction > Item Attribute KNN Algorithm]\n",
      "\n",
      "train data:: 11090 users and 413 items (152496 interactions) | sparsity:: 96.67%\n",
      "test data:: 10551 users and 333 items (38125 interactions) | sparsity:: 98.91%\n",
      "\n",
      "training_time:: 4.115911 sec\n",
      "prediction_time:: 0.150105 sec\n",
      "Eval:: MAE: 0.685754 RMSE: 0.900496 \n"
     ]
    }
   ],
   "source": [
    "ItemAttributeKNN(\n",
    "    train_file='precomputed/train.csv',\n",
    "    test_file='precomputed/test.csv',\n",
    "    output_file='outputs/aural_predictions.csv',\n",
    "    as_similar_first=True,\n",
    "    k_neighbors=5,\n",
    "    similarity_file='precomputed/item_cos_aural_sim.csv',\n",
    ").compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "791a3a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Case Recommender: Rating Prediction > Item Attribute KNN Algorithm]\n",
      "\n",
      "train data:: 11090 users and 413 items (152496 interactions) | sparsity:: 96.67%\n",
      "test data:: 10551 users and 333 items (38125 interactions) | sparsity:: 98.91%\n",
      "\n",
      "training_time:: 4.456880 sec\n",
      "prediction_time:: 0.159817 sec\n",
      "Eval:: MAE: 0.703411 RMSE: 0.924584 \n"
     ]
    }
   ],
   "source": [
    "ItemAttributeKNN(\n",
    "    train_file='precomputed/train.csv',\n",
    "    test_file='precomputed/test.csv',\n",
    "    output_file='outputs/visual_predictions.csv',\n",
    "    as_similar_first=True,\n",
    "    k_neighbors=5,\n",
    "    similarity_file='precomputed/item_cos_visual_sim.csv',\n",
    ").compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8629ceee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Case Recommender: Rating Prediction > Item Attribute KNN Algorithm]\n",
      "\n",
      "train data:: 11090 users and 413 items (152496 interactions) | sparsity:: 96.67%\n",
      "test data:: 10551 users and 333 items (38125 interactions) | sparsity:: 98.91%\n",
      "\n",
      "training_time:: 4.299709 sec\n",
      ">> metadata:: 231 items and 1979 metadata (6274 interactions) | sparsity:: 98.63%\n",
      "prediction_time:: 0.285116 sec\n",
      "Eval:: MAE: 0.72457 RMSE: 0.953339 \n"
     ]
    }
   ],
   "source": [
    "ItemAttributeKNN(\n",
    "    train_file='precomputed/train.csv',\n",
    "    test_file='precomputed/test.csv',\n",
    "    output_file='outputs/hybrid_predictions.csv',\n",
    "    as_similar_first=True,\n",
    "    k_neighbors=5,\n",
    "    similarity_file='precomputed/item_hybrid_sim.csv',\n",
    "    metadata_file='precomputed/tags.csv', \n",
    ").compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36e4d09",
   "metadata": {},
   "source": [
    "O desempenho do modelo híbrido é similar aos demais modelos. Seu desempenho foi bom, porém não é o melhor modelo. Talvez, mais testes com os parâmetros revelem uma configuração em que o modelo híbrido se sai melhor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07c9b0b",
   "metadata": {},
   "source": [
    "***Exercício 02:*** Vamos implementar um recomendador híbrido canalizado em cascata, no cenário de ranqueamento. A ideia é que um primeiro algoritmo gere uma lista C1 de N=50 itens candidatos à recomendação para cada usuário. Em seguida, um outro recomendador irá gerar uma outra lista C2 também de N=50 itens candidatos à rcomendação para cada usuário. Por fim, o ranking final será a intersecção entre C1 e C2, sendo o score de cada itens formado pela média aritmética dos scores de cada lista. Avalie o desempenho.\n",
    "\n",
    "Dica 1: utilize o parâmetro rank_length disponível nos algoritmos de ranqueamento do CaseRecommender para especificar o tamanho N de recomendações para cada usuário.\n",
    "\n",
    "Dica 2: você pode gravar num arquivo os rankings gerados por um algoritmo para cada usuário especificando o nome do arquivo no parâmetro output_file.\n",
    "\n",
    "Dica 3: consulte a Aula 04 que contém algumas métricas de avaliação de ranqueamento. Como você irá gerar o ranking final externamente ao CaseRecommender, será necessário avaliá-lo usando funções próprias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5b6e4480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def recommend(df, pred, userId, n=10):\n",
    "#     # Get the top N recommendations\n",
    "#     top_n = pred[pred['userId'] == userId].sort_values(by='prediction', ascending=False).head(n)\n",
    "    \n",
    "#     return top_n.drop(columns='userId')\n",
    "\n",
    "# def ordered_intersection(*lists):\n",
    "#     # Start with the first list\n",
    "#     if not lists:\n",
    "#         return []\n",
    "    \n",
    "#     # Create a set of all elements that appear in every list\n",
    "#     all_sets = [set(lst) for lst in lists]\n",
    "#     common_elements = set.intersection(*all_sets)\n",
    "    \n",
    "#     # Preserve the order of elements as they appear in the first list\n",
    "#     return [item for item in lists[0] if item in common_elements]\n",
    "\n",
    "# def hybrid_recommend(df, predictions, userId, n=10):\n",
    "#     recommendations = [recommend(df, pred, userId, n)['movieId'].to_list() for pred in predictions]\n",
    "#     return ordered_intersection(*recommendations)\n",
    "\n",
    "# Helper function to calculate Precision@K\n",
    "def precision_at_k(df, k):\n",
    "    relevant_items = df[df['rating'] > 0]\n",
    "    top_k_items = df.groupby('userId').head(k)\n",
    "    precision = top_k_items[top_k_items['rating'] > 0].shape[0] / top_k_items.shape[0]\n",
    "    return precision\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "562a08ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Case Recommender: Item Recommendation > UserKNN Algorithm]\n",
      "\n",
      "train data:: 11090 users and 413 items (152496 interactions) | sparsity:: 96.67%\n",
      "test data:: 10551 users and 333 items (38125 interactions) | sparsity:: 98.91%\n",
      "\n",
      "training_time:: 29.029569 sec\n",
      "prediction_time:: 96.665291 sec\n",
      "\n",
      "\n",
      "Eval:: PREC@1: 0.440337 PREC@3: 0.320507 PREC@5: 0.263937 PREC@10: 0.19183 RECALL@1: 0.143184 RECALL@3: 0.295854 RECALL@5: 0.395645 RECALL@10: 0.560795 MAP@1: 0.440337 MAP@3: 0.531213 MAP@5: 0.53265 MAP@10: 0.501229 NDCG@1: 0.440337 NDCG@3: 0.617644 NDCG@5: 0.633825 NDCG@10: 0.623731 \n",
      "[Case Recommender: Item Recommendation > ItemKNN Algorithm]\n",
      "\n",
      "train data:: 11090 users and 413 items (152496 interactions) | sparsity:: 96.67%\n",
      "test data:: 10551 users and 333 items (38125 interactions) | sparsity:: 98.91%\n",
      "\n",
      "training_time:: 1.245062 sec\n",
      "prediction_time:: 25.802659 sec\n",
      "\n",
      "\n",
      "Eval:: PREC@1: 0.419012 PREC@3: 0.305437 PREC@5: 0.252829 PREC@10: 0.187148 RECALL@1: 0.135091 RECALL@3: 0.28026 RECALL@5: 0.378824 RECALL@10: 0.54628 MAP@1: 0.419012 MAP@3: 0.511176 MAP@5: 0.51471 MAP@10: 0.484573 NDCG@1: 0.419012 NDCG@3: 0.598206 NDCG@5: 0.615788 NDCG@10: 0.607602 \n"
     ]
    }
   ],
   "source": [
    "from caserec.recommenders.item_recommendation.userknn import UserKNN\n",
    "from caserec.recommenders.item_recommendation.itemknn import ItemKNN\n",
    "\n",
    "# Definindo o tamanho do ranking\n",
    "rank_length = 50\n",
    "\n",
    "# Gerando C1 usando UserKNN\n",
    "user_knn = UserKNN(\n",
    "    train_file='precomputed/train.csv',\n",
    "    test_file='precomputed/test.csv',\n",
    "    output_file='outputs/rankings_1.csv',\n",
    "    rank_length=rank_length\n",
    ")\n",
    "\n",
    "user_knn.compute()\n",
    "\n",
    "\n",
    "# Gerando C2 usando ItemKNN\n",
    "item_knn = ItemKNN(\n",
    "    train_file='precomputed/train.csv',\n",
    "    test_file='precomputed/test.csv',\n",
    "    output_file='outputs/rankings_2.csv',\n",
    "    rank_length=rank_length\n",
    ")\n",
    "\n",
    "item_knn.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b44cb7bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>pred_1</th>\n",
       "      <th>pred_2</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>28.469562</td>\n",
       "      <td>2.403147</td>\n",
       "      <td>15.436355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>25.500807</td>\n",
       "      <td>2.320786</td>\n",
       "      <td>13.910797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>17.919954</td>\n",
       "      <td>1.986250</td>\n",
       "      <td>9.953102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>15.556132</td>\n",
       "      <td>1.782764</td>\n",
       "      <td>8.669448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>15.153696</td>\n",
       "      <td>1.977851</td>\n",
       "      <td>8.565774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457788</th>\n",
       "      <td>11089</td>\n",
       "      <td>0</td>\n",
       "      <td>2.220316</td>\n",
       "      <td>0.930920</td>\n",
       "      <td>1.575618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457790</th>\n",
       "      <td>11089</td>\n",
       "      <td>50</td>\n",
       "      <td>2.201432</td>\n",
       "      <td>0.879181</td>\n",
       "      <td>1.540307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457789</th>\n",
       "      <td>11089</td>\n",
       "      <td>9</td>\n",
       "      <td>2.211722</td>\n",
       "      <td>0.721707</td>\n",
       "      <td>1.466714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457786</th>\n",
       "      <td>11089</td>\n",
       "      <td>103</td>\n",
       "      <td>2.257446</td>\n",
       "      <td>0.639067</td>\n",
       "      <td>1.448256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457791</th>\n",
       "      <td>11089</td>\n",
       "      <td>59</td>\n",
       "      <td>1.704305</td>\n",
       "      <td>0.789219</td>\n",
       "      <td>1.246762</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>457792 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        userId  movieId     pred_1    pred_2       pred\n",
       "0            0       12  28.469562  2.403147  15.436355\n",
       "1            0       19  25.500807  2.320786  13.910797\n",
       "2            0       22  17.919954  1.986250   9.953102\n",
       "3            0       57  15.556132  1.782764   8.669448\n",
       "4            0       30  15.153696  1.977851   8.565774\n",
       "...        ...      ...        ...       ...        ...\n",
       "457788   11089        0   2.220316  0.930920   1.575618\n",
       "457790   11089       50   2.201432  0.879181   1.540307\n",
       "457789   11089        9   2.211722  0.721707   1.466714\n",
       "457786   11089      103   2.257446  0.639067   1.448256\n",
       "457791   11089       59   1.704305  0.789219   1.246762\n",
       "\n",
       "[457792 rows x 5 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the rankings\n",
    "rankings_1 = pd.read_csv('outputs/rankings_1.csv', sep='\\t', names=['userId', 'movieId', 'pred_1'])\n",
    "rankings_2 = pd.read_csv('outputs/rankings_2.csv', sep='\\t', names=['userId', 'movieId', 'pred_2'])\n",
    "\n",
    "# Merging the rankings\n",
    "hybrid_rankings = pd.merge(rankings_1, rankings_2, on=['userId', 'movieId'])\n",
    "hybrid_rankings = hybrid_rankings.fillna(0)\n",
    "\n",
    "# Get average score\n",
    "hybrid_rankings['pred'] = (hybrid_rankings['pred_1'] + hybrid_rankings['pred_2']) / 2\n",
    "\n",
    "# Filtering for intersection\n",
    "hybrid_rankings = hybrid_rankings[\n",
    "    (hybrid_rankings['pred_1'] > 0)\n",
    "    & (hybrid_rankings['pred_2'] > 0)\n",
    "]\n",
    "\n",
    "# Sorting the final rankings\n",
    "final_rankings = hybrid_rankings.sort_values(by=['userId', 'pred'], ascending=[True, False])\n",
    "\n",
    "final_rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a80ac2d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>pred_1</th>\n",
       "      <th>pred_2</th>\n",
       "      <th>pred</th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>28.469562</td>\n",
       "      <td>2.403147</td>\n",
       "      <td>15.436355</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Star Wars: Episode V - The Empire Strikes Back...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>7.402471</td>\n",
       "      <td>0.750946</td>\n",
       "      <td>4.076709</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Masters of the Universe (1987)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>5.280536</td>\n",
       "      <td>1.314397</td>\n",
       "      <td>3.297466</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Apocalypto (2006)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.275248</td>\n",
       "      <td>0.946687</td>\n",
       "      <td>2.610968</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Enemy Mine (1985)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>20.382487</td>\n",
       "      <td>2.885046</td>\n",
       "      <td>11.633767</td>\n",
       "      <td>3.0</td>\n",
       "      <td>While You Were Sleeping (1995)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId     pred_1    pred_2       pred  rating  \\\n",
       "0       0       12  28.469562  2.403147  15.436355     5.0   \n",
       "1       0       11   7.402471  0.750946   4.076709     3.5   \n",
       "2       0        6   5.280536  1.314397   3.297466     5.0   \n",
       "3       0        0   4.275248  0.946687   2.610968     5.0   \n",
       "4       1       20  20.382487  2.885046  11.633767     3.0   \n",
       "\n",
       "                                               title  \n",
       "0  Star Wars: Episode V - The Empire Strikes Back...  \n",
       "1                     Masters of the Universe (1987)  \n",
       "2                                  Apocalypto (2006)  \n",
       "3                                  Enemy Mine (1985)  \n",
       "4                     While You Were Sleeping (1995)  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "# Reading the ground truth ratings\n",
    "test_ratings = pd.read_csv('precomputed/test.csv', sep='\\t', names=['userId', 'movieId', 'rating', 'title'])\n",
    "\n",
    "# Merging\n",
    "eval_data = pd.merge(final_rankings, test_ratings, on=['userId', 'movieId'])\n",
    "\n",
    "eval_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ffa94858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mean Squared Error (MSE): 50.60468100644268'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = mean_squared_error(eval_data['rating'], eval_data['pred'])\n",
    "\n",
    "f\"Mean Squared Error (MSE): {mse}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5169d9e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mean Absolute Error (MAE): 5.559783997003632'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae = mean_absolute_error(eval_data['rating'], eval_data['pred'])\n",
    "\n",
    "f\"Mean Absolute Error (MAE): {mae}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9b4422f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Precision@5: 1.0'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate Precision@K for K=5\n",
    "precision_k = precision_at_k(eval_data, 5)\n",
    "\n",
    "f\"Precision@5: {precision_k}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7cfb6f5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>pred_1</th>\n",
       "      <th>pred_2</th>\n",
       "      <th>pred</th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>28.469562</td>\n",
       "      <td>2.403147</td>\n",
       "      <td>2.403147</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Star Wars: Episode V - The Empire Strikes Back...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>7.402471</td>\n",
       "      <td>0.750946</td>\n",
       "      <td>0.750946</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Masters of the Universe (1987)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>5.280536</td>\n",
       "      <td>1.314397</td>\n",
       "      <td>1.314397</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Apocalypto (2006)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.275248</td>\n",
       "      <td>0.946687</td>\n",
       "      <td>2.610968</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Enemy Mine (1985)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>20.382487</td>\n",
       "      <td>2.885046</td>\n",
       "      <td>2.885046</td>\n",
       "      <td>3.0</td>\n",
       "      <td>While You Were Sleeping (1995)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId     pred_1    pred_2      pred  rating  \\\n",
       "0       0       12  28.469562  2.403147  2.403147     5.0   \n",
       "1       0       11   7.402471  0.750946  0.750946     3.5   \n",
       "2       0        6   5.280536  1.314397  1.314397     5.0   \n",
       "3       0        0   4.275248  0.946687  2.610968     5.0   \n",
       "4       1       20  20.382487  2.885046  2.885046     3.0   \n",
       "\n",
       "                                               title  \n",
       "0  Star Wars: Episode V - The Empire Strikes Back...  \n",
       "1                     Masters of the Universe (1987)  \n",
       "2                                  Apocalypto (2006)  \n",
       "3                                  Enemy Mine (1985)  \n",
       "4                     While You Were Sleeping (1995)  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_data_filtered = eval_data.copy()\n",
    "eval_data_filtered.loc[eval_data_filtered['pred_1'] > 5, 'pred'] = eval_data_filtered['pred_2']\n",
    "eval_data_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e8a497a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mean Squared Error (MSE): 2.7831567810143687'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = mean_squared_error(eval_data_filtered['rating'], eval_data_filtered['pred'])\n",
    "\n",
    "f\"Mean Squared Error (MSE): {mse}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "79f30f5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mean Absolute Error (MAE): 1.3841018758171912'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae = mean_absolute_error(eval_data_filtered['rating'], eval_data_filtered['pred'])\n",
    "\n",
    "f\"Mean Absolute Error (MAE): {mae}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c0e1e0da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Precision@5: 1.0'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate Precision@K for K=5\n",
    "precision_k = precision_at_k(eval_data_filtered, 5)\n",
    "\n",
    "f\"Precision@5: {precision_k}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1d478b",
   "metadata": {},
   "source": [
    "O desempenho é ruim segundo as métricas baseadas em médias. Isso provavelmente ocorre porque a predição 1 está repleta de outliers, o que distorce a média. Ao remover esses outliers, a qualidade da predição melhora significativamente. Além disso, devido à sua alta precisão, o modelo híbrido apresenta uma grande proporção de itens relevantes entre as recomendações feitas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
